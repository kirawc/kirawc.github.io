<!DOCTYPE html>
<html>

  <head>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <link rel="stylesheet" href="index.css">
    <script src="index.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" href="cat.svg" type="image/x-icon">

  </head>

  <body>

    <div class=header>
      <div class="name">Kira Wegner-Clemens, PhD</div>

      <div class="title">cognitive neuroscientist</div>

      <div class="navbar">
        <a href="#" id="homebutton" class="button">home</a>
        <a href="#" id="projbutton" class="button">research</a>
        <a href="#" id="pubbutton" class="button">publications</a>
        <a href="cv_kwegnerclemens.pdf">cv</a>
        <a href="https://scholar.google.com/citations?user=tAiYT2IAAAAJ&hl=en&oi=ao">google scholar</a>
      </div>

    </div>

    <div class="mainbox">
      <div class="sidebar">

        <div class="photo">
          <img src = "pic.jpg" width="150px"></img>
        </div>
      
      <div class="contact">
        kw1021
        @ georgetown edu 
      </div>
    </div>

    <div class="contentbox">

      <div class="intro">

    Hi! I'm a postdoctoral fellow at Georgetown University.
    <br><br>
    My research focuses on multisensory processing and attention.
    <br><br>
    I completed my PhD at George Washington University, where my dissertation focused on how semantic understanding guides attention in audiovisual contexts.
    <br><br>
    Before grad school, I recieved my BA from Rice University and worked as a post bac researcher at Baylor College of Medicine. 
      </div>

      <div class="pub">
           <u>2024</u>
          <br><br>
          <b>Wegner-Clemens, K.</b>, Malcolm, G. L., Shomstein, S. (2024)
          Predicting attention in real-world environments: the need to investigate crossmodal semantic guidance.
          <i>WIRES Cognitive Science.</i>
          <a href="https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wcs.1675"> (link) </a>
          <br><br>
          <u>2022</u>
          <br><br>
        <b>Wegner-Clemens, K.</b>, Malcolm, G. L., Shomstein, S. (2022)
        How much is a cow like a meow? A novel database of human judgements of audiovisual semantic relatedness.
        <i>Attention, Perception, & Psychophysics.</i>
        (<a href="https://link.springer.com/article/10.3758/s13414-022-02488-1"> link; </a>
        <a href="https://psyarxiv.com/7h82c/"> preprint </a>)

        <br><br><br>
        <u>2020</u>
        <br><br>

        Magnotti, J.F., Dzeda, K.B., <b>Wegner-Clemens, K.</b>, Rennig, J., & Beauchamp, M.S. (2020).
        Weak observer-level correlation and strong stimulus-level correlation between the McGurk effect and
        audiovisual speech-in-noise: a causal inference explanation.</a> <i>Cortex.</i> doi:10.1016/j.cortex.2020.10.002
        (<a href = "pubs/Magnotti_et_al_Cortex_2020.pdf">pdf</a>; <a href="https://www.sciencedirect.com/science/article/pii/S0010945220303749">link</a>)

        <br><br><br>

        <strong>Wegner-Clemens, K.</strong>, Rennig, J., & Beauchamp, M.S. (2020) A relationship
        between Autism-Spectrum Quotient and face viewing behavior in 98 participants. <i>PLoS ONE</i> 15(4): e0230866.
        (<a href="pubs/Wegner-Clemens_et_al_2020_PLOSONE.pdf">pdf</a>;
        <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230866">link</a>)


        <br><br><br>
        <u>2019</u>
        <br><br><br>

        <strong>Wegner-Clemens K</strong>, Rennig J, Magnotti JF, Beauchamp MS. (2019)
        Using principal components analysis to characterize eye movement fixation patterns during face viewing. <i>Journal of Vision</i>,
        November 2019, Vol.19, 2. doi:10.1167/19.13.2
        (<a href="pubs/Wegner-Clemens_Rennig_Magnotti_Beauchamp_JOV_2019.pdf">pdf</a>;
        <a href="https://jov.arvojournals.org/article.aspx?articleid=2755283">link</a>)

        <br><br><br>
        Rennig, J., <strong>Wegner-Clemens, K.</strong>, & Beauchamp, M.S. (2019)
        Face Viewing Behavior Predicts Multisensory Gain During Speech Perception. <i>Psychonomic Bulletin & Review</i>. 27, 70â€“77(2020)
        ( <a href="pubs/Rennig_WegnerClemens_Beauchamp_PBR2019.pdf">pdf</a>;
         <a href="https://link.springer.com/article/10.3758/s13423-019-01665-y">link</a>)

        <br><br><br>
        Convento, S., <strong>Wegner-Clemens, K. A.</strong>, & Yau, J. M. (2019).
        Reciprocal Interactions Between Audition and Touch in Flutter Frequency Perception</a>,
        <i>Multisensory Research</i>, 32(1), 67-85.
        (<a href="pubs/Convento_et_al_MultisensoryResarch.pdf">pdf</a>;
        <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7294791/">link</a>)   
      </div>

    <div class="proj">
      under construction
    </div>

    </div>

  </div>

  </body>
</html>
